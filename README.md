# ğŸ”§ Hardware Debug Assistant

**AI-powered RTL debugging assistant for Verilog & VHDL engineers**

Built with Cloudflare's Agents SDK, this application provides intelligent assistance for hardware design debugging, synthesis error analysis, and timing optimization.

---

## Project Overview

This application was developed for the Cloudflare SWE Internship application, demonstrating:

- âœ… **LLM Integration**: Llama 3.3 on Workers AI for intelligent code analysis
- âœ… **Workflow/Coordination**: Cloudflare Agents SDK with Durable Objects
- âœ… **User Input**: Real-time chat interface with streaming responses
- âœ… **Memory/State**: Persistent conversation history and design context

---

## Features

### Core Capabilities
- ğŸ› **Debug RTL Code** - Analyze Verilog/VHDL syntax and logic issues
- â±ï¸ **Timing Analysis** - Identify setup/hold violations and critical paths
- ğŸ”’ **Latch Detection** - Explain and fix inferred latches
- ğŸ”„ **CDC Issues** - Clock domain crossing best practices
- ğŸ“Š **Synthesis Guidance** - Interpret EDA tool errors and warnings
- ğŸ’¾ **Design Context** - Maintains state of current modules and recent issues

### Technical Features
- Real-time streaming responses via WebSocket
- Persistent chat history using Durable Objects SQL
- Dark/Light theme support
- Code snippet highlighting
- Context-aware suggestions based on design state
- Quick example prompts for common issues

---

## ğŸ—ï¸ Architecture

### Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 React Frontend                  â”‚
â”‚  (Vite + TypeScript + Tailwind CSS)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ WebSocket
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Cloudflare Workers (server.ts)          â”‚
â”‚  â€¢ Request routing                               â”‚
â”‚  â€¢ WebSocket handling                            â”‚
â”‚  â€¢ Agent instantiation                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    HardwareDebugAgent (Durable Object)          â”‚
â”‚  â€¢ Chat coordination                             â”‚
â”‚  â€¢ State management (this.setState)              â”‚
â”‚  â€¢ SQL database (conversation history)           â”‚
â”‚  â€¢ Tool execution                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Workers AI (LLM Provider)             â”‚
â”‚  â€¢ Llama 3.3 70B Instruct                       â”‚
â”‚  â€¢ Streaming responses                           â”‚
â”‚  â€¢ Function calling for tools                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Stack?

**Cloudflare Agents SDK**: Built-in state management, WebSocket support, and SQL storage make it perfect for conversational AI applications.

**Workers AI (Llama 3.3)**: 
- Runs on Cloudflare's network for low latency
- No external API dependencies or costs
- Strong performance on technical/code understanding tasks

**Durable Objects**: 
- Each chat session gets its own isolated instance
- Automatic state persistence
- SQL database for conversation history

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- Cloudflare account
- Wrangler CLI

### Installation

```bash
# Clone the repository
git clone https://github.com/yegane-AI/cf_ai_hardware_debug_assistant
cd hardware-debug-assistant

# Install dependencies
npm install

# Set up environment variables
cp .dev.vars.example .dev.vars
# Edit .dev.vars if needed (Workers AI requires no API key)

# Run locally
npm start

# Open http://localhost:8787
```

### Deployment

```bash
# Deploy to Cloudflare
npm run deploy

# Your app will be live at: https://hardware-debug-assistant.<your-subdomain>.workers.dev
```

---

## ğŸ“ Project Structure

```
hardware-debug-assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.tsx              # React UI (chat interface)
â”‚   â”œâ”€â”€ server.ts            # Cloudflare Worker (request handler)
â”‚   â”œâ”€â”€ agent.ts             # HardwareDebugAgent class
â”‚   â”œâ”€â”€ tools.ts             # Tool definitions (code analysis, etc.)
â”‚   â”œâ”€â”€ llm.ts               # LLM provider configuration
â”‚   â”œâ”€â”€ utils.ts             # Helper functions
â”‚   â””â”€â”€ styles.css           # Tailwind styling
â”œâ”€â”€ public/                   # Static assets
â”œâ”€â”€ wrangler.jsonc           # Cloudflare configuration
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Key Implementation Details

### 1. LLM Integration (Llama 3.3 on Workers AI)

```typescript
// src/llm.ts
import { createWorkersAI } from 'workers-ai-provider';

export function createLLMProvider(env: Env) {
  const workersai = createWorkersAI({ binding: env.AI });
  return workersai('@cf/meta/llama-3.3-70b-instruct-fp8-fast');
}
```

### 2. Agent with Memory/State

```typescript
// src/agent.ts
export class HardwareDebugAgent extends Agent {
  async handleChat(message: string) {
    // Store message in SQL
    await this.sql.exec(
      'INSERT INTO messages (role, content, timestamp) VALUES (?, ?, ?)',
      ['user', message, Date.now()]
    );
    
    // Update state (syncs to client automatically)
    await this.setState({ 
      lastMessage: message,
      messageCount: this.state.messageCount + 1 
    });
    
    // Get conversation history for context
    const history = await this.sql
      .prepare('SELECT * FROM messages ORDER BY timestamp DESC LIMIT 10')
      .all();
    
    // Call LLM with context
    const response = await this.callLLM(message, history);
    
    return response;
  }
}
```

### 3. WebSocket Real-time Communication

```typescript
// src/server.ts
export default {
  async fetch(request: Request, env: Env) {
    const upgradeHeader = request.headers.get('Upgrade');
    if (upgradeHeader === 'websocket') {
      const id = env.HardwareDebugAgent.idFromName('session-123');
      const agent = env.HardwareDebugAgent.get(id);
      return agent.fetch(request);
    }
    // ... HTTP handling
  }
}
```

### 4. Tools for Hardware Analysis

```typescript
// src/tools.ts
export const analyzeVerilogTool = tool({
  description: "Analyze Verilog/VHDL code for common issues",
  parameters: z.object({
    code: z.string(),
    language: z.enum(['verilog', 'vhdl'])
  }),
  execute: async ({ code, language }) => {
    // Perform static analysis
    const issues = detectCommonIssues(code, language);
    return { issues, suggestions: generateSuggestions(issues) };
  }
});
```

---

## ğŸ“ Technical Highlights Relevant to My Background

As a PhD student in Computer Science at UCSB with expertise in:

- **SoC Protocol Verification** â†’ Understanding hardware communication patterns helps the assistant provide accurate advice on bus protocols (AXI, AHB)
- **Hardware Security (Logic Locking)** â†’ Knowledge of secure design practices informs suggestions on protecting IP
- **ML for Hardware** â†’ Using ML models (LLMs) to analyze and debug hardware designs bridges both domains
- **RTL Design & Synthesis** â†’ First-hand experience with Verilog, synthesis tools, and timing analysis

This project demonstrates:
1. **Domain expertise** in hardware design translating to user-facing tools
2. **Full-stack development** capabilities (React + TypeScript + Cloudflare platform)
3. **AI integration** skills with modern LLM frameworks
4. **Production-ready code** with proper error handling, state management, and UX

---

## ğŸ§ª Example Interactions

**User**: "I'm getting a latch inferred warning for this code:
```verilog
always @(a or b) begin
  if (a) 
    out = b;
end
```"

**Assistant**: "I see the issue! You have an incomplete conditional assignment. When `a` is false, `out` doesn't get assigned, causing the synthesizer to infer a latch to hold the previous value.

**Fix**: Add an else clause:
```verilog
always @(a or b) begin
  if (a) 
    out = b;
  else
    out = 1'b0;  // or whatever default value you need
end
```

Or use a default assignment before the if:
```verilog
always @(a or b) begin
  out = 1'b0;  // default
  if (a) 
    out = b;
end
```"

---

## ğŸ“Š Meeting the Requirements

| Requirement | Implementation | Technology |
|------------|----------------|------------|
| **LLM** | âœ… Llama 3.3 70B Instruct | Workers AI |
| **Workflow/Coordination** | âœ… Agent class with state management | Agents SDK + Durable Objects |
| **User Input (Chat)** | âœ… Real-time WebSocket chat interface | React + WebSocket API |
| **Memory/State** | âœ… SQL storage + state sync | Durable Objects SQL + setState() |

---

## ğŸš€ Future Enhancements

- [ ] Upload Verilog/VHDL files directly
- [ ] Integration with GitHub for pull request reviews
- [ ] Voice input support (Speech-to-Text API)
- [ ] Multi-user collaboration sessions
- [ ] Connect to real EDA tools via workflows
- [ ] Formal verification suggestions using Rosette/Z3

---
